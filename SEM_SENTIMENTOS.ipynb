{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8V8f/ukKoyZf7G0UgQnBx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V70kqEzxyMep",
        "outputId": "660f370a-6875-4a19-8666-16626a96a3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AirBnbPricePrediction'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 75 (delta 7), reused 0 (delta 0), pack-reused 60 (from 1)\u001b[K\n",
            "Receiving objects: 100% (75/75), 44.83 KiB | 740.00 KiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PouyaREZ/AirBnbPricePrediction.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AirBnbPricePrediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf8OySliyYyd",
        "outputId": "07e73047-da9e-4e8c-8790-b4519455af06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AirBnbPricePrediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idf-sVLZygQ_",
        "outputId": "8bd69b10-3628-4981-a3a7-d9d143f7b07c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.16.2 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.16.2.zip (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib==2.2.2 (from -r requirements.txt (line 2))\n",
            "  Downloading matplotlib-2.2.2.tar.gz (37.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Keras==2.2.4 (from -r requirements.txt (line 3))\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting scipy==1.1.0 (from -r requirements.txt (line 4))\n",
            "  Downloading scipy-1.1.0.tar.gz (15.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas==0.24.2 (from -r requirements.txt (line 5))\n",
            "  Downloading pandas-0.24.2.tar.gz (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZiVfTy04TnH",
        "outputId": "87159ade-ba5f-41ad-8349-1dd9e788cda8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AirBnbPricePrediction/Main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_cleanup.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JatTn3DwzpLJ",
        "outputId": "7ee8e35a-1855-4e27-bad3-9aa8a68956ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:10: DtypeWarning: Columns (43,87,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(filename)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n",
            "/content/AirBnbPricePrediction/Main/data_cleanup.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data.insert(len(list(data)), amenity, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_preprocessing_reviews.py"
      ],
      "metadata": {
        "id": "9fK3w3Yr-8ET"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python feature_selection.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOSkLtZ6Cn31",
        "outputId": "41268812-7e87-4d3a-f240-cd5bac9ae7a1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(763,)\n",
            "(123,)\n",
            "Index(['host_since', 'host_total_listings_count', 'latitude', 'longitude',\n",
            "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'security_deposit',\n",
            "       'cleaning_fee',\n",
            "       ...\n",
            "       'Nolita', 'Ridgewood.1', 'SoHo', 'Sunnyside.1', 'Theater District',\n",
            "       'Tribeca', 'Upper East Side', 'Upper West Side', 'Washington Heights',\n",
            "       'West Village'],\n",
            "      dtype='object', length=123)\n",
            "['host_since', 'host_total_listings_count', 'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'review_scores_rating', 'review_scores_cleanliness', 'review_scores_location', 'Hair_dryer', 'Family/kid_friendly', 'Heating', 'Suitable_for_events', 'Pets_live_on_this_property', 'Washer', 'Dishwasher', 'Self_check-in', 'Shampoo', 'Private_entrance', 'Safety_card', 'Building_staff', 'Host_greets_you', 'TV', 'Cat(s)', 'Air_conditioning', 'Ethernet_connection', 'Coffee_maker', 'Children’s_dinnerware', 'Pool', 'Babysitter_recommendations', 'Pack_’n_Play/travel_crib', 'Dishes_and_silverware', 'Lock_on_bedroom_door', 'Crib', 'Dryer', 'Internet', 'Long_term_stays_allowed', 'Room-darkening_shades', 'Bathtub', 'Carbon_monoxide_detector', 'Luggage_dropoff_allowed', 'High_chair', 'Gym', 'Stove', 'Pets_allowed', 'Laptop_friendly_workspace', 'Kitchen', 'Buzzer/wireless_intercom', 'Doorman', 'Smoking_allowed', 'Iron', 'Patio_or_balcony', 'Oven', 'Elevator', 'Free_street_parking', 'Children’s_books_and_toys', '24-hour_check-in', 'Paid_parking_on_premises', 'Paid_parking_off_premises', 'Cable_TV', 'Cooking_basics', 'Indoor_fireplace', 'Wheelchair_accessible', 'Fire_extinguisher', 'Condominium', 'House', 'Loft', 'Resort', 'Serviced apartment', 'Real Bed', 'Entire home/apt', 'Private room', 'Shared room', 'Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Bronx.1', 'Brooklyn.1', 'Brooklyn ', 'New York', 'Queens.1', 'flexible', 'moderate', 'strict_14_with_grace_period', 'super_strict_30', 'super_strict_60', 'within a few hours', 'Astoria.1', 'Bedford-Stuyvesant.1', 'Bushwick.1', 'Chelsea', 'Crown Heights', 'East Flatbush', 'East Village', 'Elmhurst.1', 'Financial District', 'Flatbush', 'Flatiron District', 'Flushing.1', 'Gramercy', 'Greenwich Village', 'Harlem.1', \"Hell's Kitchen\", 'Kips Bay.1', 'Midtown', 'Murray Hill', 'Nolita', 'Ridgewood.1', 'SoHo', 'Sunnyside.1', 'Theater District', 'Tribeca', 'Upper East Side', 'Upper West Side', 'Washington Heights', 'West Village']\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjBsxFYOM2GQ",
        "outputId": "e258904a-8e0f-4798-d518-94d6d87efc75"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.0\n",
            "Uninstalling tensorflow-2.17.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.17.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "Y\n",
            "y\n",
            "\n",
            "  Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: keras 3.4.1\n",
            "Uninstalling keras-3.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/keras-3.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/keras/*\n",
            "Proceed (Y/n)?   Successfully uninstalled keras-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDsASjMqNlJw",
        "outputId": "0e8fa01c-3e4d-421d-9f53-06cfed7f4690"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras, tensorflow\n",
            "Successfully installed keras-3.5.0 tensorflow-2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_models.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdjZESQxN_7K",
        "outputId": "e28001b8-361d-4e1d-83ec-347d315a5cd6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-05 23:27:42.385445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-05 23:27:42.412960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-05 23:27:42.422515: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-05 23:27:42.442610: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-05 23:27:44.307123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "--------------------Tree-based Model--------------------\n",
            "--------- For Model:  Gradient Boost  ---------\n",
            "\n",
            "Mean absolute error:  0.3403909920169041\n",
            "Median absolute error:  0.266300499318769\n",
            "Mean squared error:  0.21151920695967114\n",
            "R2:  0.5543744242511648\n",
            "--------- For Model:  Gradient Boost  --------- (Train Data)\n",
            "\n",
            "Mean absolute error:  0.2538582634431393\n",
            "Median absolute error:  0.17867361833961448\n",
            "Mean squared error:  0.14240458982219575\n",
            "R2:  0.7020524617119892\n",
            "--------------------KMeans Clustering--------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AirBnbPricePrediction/Main/run_models.py\", line 281, in <module>\n",
            "    c_pred, centroids = kmeans(X_concat, y_concat, X_test, y_test)\n",
            "  File \"/content/AirBnbPricePrediction/Main/run_models.py\", line 164, in kmeans\n",
            "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, verbose=0, n_jobs=int(0.8*n_cores)).fit(X_train)\n",
            "TypeError: KMeans.__init__() got an unexpected keyword argument 'n_jobs'\n"
          ]
        }
      ]
    }
  ]
}